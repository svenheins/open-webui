services:
  ollama:
    volumes:
      - ollama:/root/.ollama
    container_name: ollama
#    pull_policy: always
    tty: true
    restart: unless-stopped
    image: ollama/ollama:${OLLAMA_DOCKER_TAG-latest}
    networks:
      - open-webui

  pipelines-base:
    build:
      context: pipelines
      dockerfile: Dockerfile_base
    environment:
      - no_proxy=${no_proxy}
      - NO_PROXY=${NO_PROXY}
    volumes:
      - ./pipelines/mount/base:/app/pipelines 
      - .env:/app/pipelines/.env
    depends_on:
      - ollama
    container_name: pipelines-base
    tty: true
    restart: unless-stopped
    ports:
      - 11435:11434
    networks:
      - open-webui

  pipelines-crewai:
    build:
      context: pipelines
      dockerfile: Dockerfile_crewai
    environment:
      - no_proxy=${no_proxy}
      - NO_PROXY=${NO_PROXY}
    volumes:
      - ./pipelines/mount/crewai:/app/pipelines 
      - .env:/app/pipelines/.env
    depends_on:
      - ollama
    container_name: pipelines-crewai
    tty: true
    restart: unless-stopped
    networks:
      - open-webui

  pipelines-neo4j-agents:
    build:
      context: pipelines
      dockerfile: Dockerfile_neo4j_agents
    volumes:
      - ./pipelines/mount/neo4j_agents:/app/pipelines 
      - .env:/app/pipelines/.env
    environment:
      - no_proxy=${no_proxy}
      - NO_PROXY=${NO_PROXY}
    depends_on:
      ollama:
        condition: service_started
      neo4j:
        condition: service_healthy
    container_name: pipelines-neo4j-agents
    tty: true
    restart: unless-stopped
    networks:
      - open-webui

  pipelines-weblink-youtube:
    build:
      context: pipelines
      dockerfile: Dockerfile_weblink_youtube
    volumes:
      - ./pipelines/mount/weblink_youtube:/app/pipelines 
      - .env:/app/pipelines/.env
    environment:
      - no_proxy=${no_proxy}
      - NO_PROXY=${NO_PROXY}
    depends_on:
      - ollama
    container_name: pipelines-weblink-youtube
    tty: true
    restart: unless-stopped
    networks:
      - open-webui

  open-webui:
    #build:
    #  context: .
    #  args:
    #    OLLAMA_BASE_URL: '/ollama'
    #  dockerfile: Dockerfile
    image: ghcr.io/open-webui/open-webui:${WEBUI_DOCKER_TAG-main}
    container_name: open-webui
    environment:
      - no_proxy=${no_proxy}
      - NO_PROXY=${NO_PROXY}
    volumes:
      - open-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - ${OPEN_WEBUI_PORT-3000}:8080
    #extra_hosts:
    #  - host.docker.internal:host-gateway
    restart: unless-stopped
    networks:
      - open-webui

  neo4j:
    image: neo4j:5.20.0-community-bullseye
    container_name: neo4j
    environment:
      - NEO4J_AUTH=${NEO4J_USER}/${NEO4J_PASSWORD}
    ports:
      - 7474:7474
      - 7687:7687
    healthcheck:
      test: wget http://localhost:7474 || exit 1
      interval: 1s
      timeout: 10s
      retries: 20
      start_period: 3s
    volumes:
      - ./graph-module/neo4j/data:/data
      - ./graph-module/neo4j/logs:/logs
      - ./graph-module/neo4j/import:/var/lib/neo4j/import
      - ./graph-module/neo4j/plugins:/plugins
    networks:
      - open-webui


volumes:
  ollama: {}
  open-webui: {}
  pipelines: {}

networks:
  open-webui:
